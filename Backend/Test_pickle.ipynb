{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "url = 'https://www.foxnews.com/politics/supreme-court-strikes-down-state-ban-on-taxpayer-funding-for-religious-schools'\n",
    "article = Article(url)\n",
    "article.download()\n",
    "article.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = {'title': [article.title],'text': [article.text]}\n",
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supreme Court strikes down state ban on taxpay...</td>\n",
       "      <td>The Supreme Court on Tuesday struck down a ban...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Supreme Court strikes down state ban on taxpay...   \n",
       "\n",
       "                                                text  \n",
       "0  The Supreme Court on Tuesday struck down a ban...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(X):\n",
    "    #remove digits \n",
    "    #remove words less than 3 characters \n",
    "    #remove punctuation\n",
    "\n",
    "    X['clean_title'] = X['title'].str.replace('\\d+', ' ') # for digits\n",
    "    X['clean_title'] = X['clean_title'].str.replace(r'(\\b\\w{1,2}\\b)', ' ') # for words less than 3 characters\n",
    "    X['clean_title'] = X['clean_title'].str.replace('[^\\w\\s]', ' ') # for punctuation \n",
    "    \n",
    "    X['clean_text'] = X['text'].str.replace('\\d+', ' ') # for digits\n",
    "    X['clean_text'] = X['clean_text'].str.replace(r'(\\b\\w{1,2}\\b)', ' ') # for words less than 3 characters\n",
    "    X['clean_text'] = X['clean_text'].str.replace('[^\\w\\s]', ' ') # for punctuation \n",
    "    #lemmatization \n",
    "    X['clean_title'] = X['clean_title'] .apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    X['clean_text'] = X['clean_text'] .apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    return X\n",
    "\n",
    "def makeCV_vector(df):\n",
    "    #loading CountVec object\n",
    "    cv_vector_title = pickle.load(open('cv_1-3_vector_title.sav','rb'))\n",
    "    cv_vector_text = pickle.load(open('cv_1-3_vector_text.sav','rb'))\n",
    "    \n",
    "    vector_title = cv_vector_title.transform(df['clean_title'].values.astype('U'))\n",
    "    vectorized_title = pd.DataFrame(vector_test_title.toarray(), columns=cv_vector_title.get_feature_names())\n",
    "    \n",
    "    vector_text = cv_vector_text.transform(df['clean_text'].values.astype('U'))\n",
    "    vectorized_text = pd.DataFrame(vector_test_text.toarray(), columns=cv_vector_text.get_feature_names())\n",
    "    \n",
    "    #combine test title and text\n",
    "    vectorized_cv = pd.concat([vectorized_title, vectorized_text], axis=1)\n",
    "    return vectorized_cv\n",
    "    \n",
    "def makeTFIDF_vector(df):\n",
    "    #loading TF-IDF object\n",
    "    tfidf_vector_title = pickle.load(open('tfidf_1-3_vector_title.sav','rb'))\n",
    "    tfidf_vector_text = pickle.load(open('tfidf_1-3_vector_text.sav','rb'))\n",
    "    \n",
    "    vector_title = tfidf_vector_title.transform(df['clean_title'].values.astype('U'))\n",
    "    vectorized_title = pd.DataFrame(vector_title.toarray(), columns=tfidf_vector_title.get_feature_names())\n",
    "\n",
    "    vector_text = tfidf_vector_text.transform(df['clean_text'].values.astype('U'))\n",
    "    vectorized_text = pd.DataFrame(vector_text.toarray(), columns=tfidf_vector_text.get_feature_names())\n",
    "    \n",
    "    vectorized_tfidf = pd.concat([vectorized_title, vectorized_text], axis=1)\n",
    "    return vectorized_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataset(df)\n",
    "vectorized_cv = makeCV_vector(df)\n",
    "vectorized_tfidf = makeTFIDF_vector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chi/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/chi/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#loading SVM model\n",
    "svm = pickle.load(open('SVM_tfidf_1-3.sav','rb'))\n",
    "\n",
    "#loading Random Forest model\n",
    "rf = pickle.load(open('RandomForest_model_countvec_trigram.sav','rb'))\n",
    "\n",
    "#loading other models....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = svm.predict_proba(vectorized_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust rating: 62\n"
     ]
    }
   ],
   "source": [
    "print(\"Trust rating: %.0f\" %(prediction[0][1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = rf.predict_proba(vectorized_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust rating: 47\n"
     ]
    }
   ],
   "source": [
    "print(\"Trust rating: %.0f\" %(prediction2[0][1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other models' prediction....."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
