{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/adityasoni/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adityasoni/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adityasoni/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string \n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import Word\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vectorizer(train_data, test_data, ngram):\n",
    "    #train title data\n",
    "    countVec_title = CountVectorizer(lowercase=True, stop_words='english', min_df =0.01, ngram_range= ngram, strip_accents='ascii')\n",
    "    #vector_train_title = countVec_title.fit_transform(train_data['clean_title'].values.astype('U'))\n",
    "    vector_train_title = countVec_title.fit_transform(train_data['clean_title'])\n",
    "    tokens_title = countVec_title.get_feature_names()\n",
    "    vectorized_train_title = pd.DataFrame(vector_train_title.toarray(), columns=tokens_title)\n",
    "    \n",
    "    #test title data - only transform\n",
    "#    vector_test_title = countVec_title.transform(test_data['clean_title'].values.astype('U'))\n",
    "    vector_test_title = countVec_title.transform(test_data['clean_title'])\n",
    "    vectorized_test_title = pd.DataFrame(vector_test_title.toarray(), columns=tokens_title)\n",
    "\n",
    "    #train text data\n",
    "    countVec_text = CountVectorizer(lowercase=True, stop_words='english', min_df =0.01, ngram_range= ngram, strip_accents='ascii')\n",
    "    #vector_train_text = countVec_text.fit_transform(train_data['clean_text'].values.astype('U'))\n",
    "    vector_train_text = countVec_text.fit_transform(train_data['clean_text'])\n",
    "    tokens_text = countVec_text.get_feature_names()\n",
    "    vectorized_train_text = pd.DataFrame(vector_train_text.toarray(), columns=tokens_text)\n",
    "    \n",
    "    #test text data - only transform\n",
    "    #vector_test_text = countVec_text.transform(test_data['clean_text'].values.astype('U'))\n",
    "    vector_test_text = countVec_text.transform(test_data['clean_text'])\n",
    "    vectorized_test_text = pd.DataFrame(vector_test_text.toarray(), columns=tokens_text)\n",
    "\n",
    "    #combine train data and test data features\n",
    "    vectorized_train = pd.concat([vectorized_train_title, vectorized_train_text], axis=1)\n",
    "    vectorized_test = pd.concat([vectorized_test_title, vectorized_test_text], axis=1)\n",
    "    return vectorized_train, vectorized_test\n",
    "\n",
    "def tfidf_vectorizer(train_data, test_data, ngram):\n",
    "    #train title data\n",
    "    tfidfVec_title = TfidfVectorizer(lowercase=True, stop_words='english', min_df =0.01, ngram_range= ngram, strip_accents='ascii')\n",
    "#    vector_train_title = tfidfVec_title.fit_transform(train_data['clean_title'].values.astype('U'))\n",
    "    vector_train_title = tfidfVec_title.fit_transform(train_data['clean_title'])\n",
    "    tokens_title = tfidfVec_title.get_feature_names()\n",
    "    vectorized_train_title = pd.DataFrame(vector_train_title.toarray(), columns=tokens_title)\n",
    "    \n",
    "    #test title data - only transform\n",
    "#    vector_test_title = tfidfVec_title.transform(test_data['clean_title'].values.astype('U'))\n",
    "    vector_test_title = tfidfVec_title.transform(test_data['clean_title'])\n",
    "    vectorized_test_title = pd.DataFrame(vector_test_title.toarray(), columns=tokens_title)\n",
    "\n",
    "    #train text data\n",
    "    tfidfVec_text = TfidfVectorizer(lowercase=True, stop_words='english', min_df =0.01, ngram_range= ngram, strip_accents='ascii')\n",
    "#    vector_train_text = tfidfVec_text.fit_transform(train_data['clean_text'].values.astype('U'))\n",
    "    vector_train_text = tfidfVec_text.fit_transform(train_data['clean_text'])\n",
    "    tokens_text = tfidfVec_text.get_feature_names()\n",
    "    vectorized_train_text = pd.DataFrame(vector_train_text.toarray(), columns=tokens_text)\n",
    "    \n",
    "    #test text data - only transform\n",
    "#    vector_test_text = tfidfVec_text.transform(test_data['clean_text'].values.astype('U'))\n",
    "    vector_test_text = tfidfVec_text.transform(test_data['clean_text'])\n",
    "    vectorized_test_text = pd.DataFrame(vector_test_text.toarray(), columns=tokens_text)\n",
    "\n",
    "    #combine train data and test data features\n",
    "    vectorized_train = pd.concat([vectorized_train_title, vectorized_train_text], axis=1)\n",
    "    vectorized_test = pd.concat([vectorized_test_title, vectorized_test_text], axis=1)\n",
    "    return vectorized_train, vectorized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Dataset to be tried\n",
    "data = pd.read_csv(\"newData_w_title.csv\")\n",
    "\n",
    "#data.shape\n",
    "#data.head()\n",
    "\n",
    "\n",
    "X = pd.DataFrame(data[['title', 'text']])\n",
    "y = pd.DataFrame(data['label'])\n",
    "\n",
    "\n",
    "X['clean_title'] = X['title'].str.replace('\\d+', ' ') # for digits\n",
    "X['clean_title'] = X['clean_title'].str.replace(r'(\\b\\w{1,2}\\b)', ' ') # for words less than 3 characters\n",
    "X['clean_title'] = X['clean_title'].str.replace('[^\\w\\s]', ' ') # for punctuation \n",
    "    \n",
    "X['clean_text'] = X['text'].str.replace('\\d+', ' ') # for digits\n",
    "X['clean_text'] = X['clean_text'].str.replace(r'(\\b\\w{1,2}\\b)', ' ') # for words less than 3 characters\n",
    "X['clean_text'] = X['clean_text'].str.replace('[^\\w\\s]', ' ') # for punctuation \n",
    "    \n",
    "#lemmatization \n",
    "X['clean_title'] = X['clean_title'] .apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "X['clean_text'] = X['clean_text'] .apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    \n",
    "    \n",
    "#Split to train and test dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000)\n",
    "\n",
    "#Reset all the index\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorize\n",
    "#ngram = (1,1)\n",
    "#train_data_uni, test_data_uni = count_vectorizer(X_train, X_test, ngram)\n",
    "\n",
    "#Count Vectorize\n",
    "#ngram = (1,2)\n",
    "#train_data_bi, test_data_bi = count_vectorizer(X_train, X_test, ngram)\n",
    "\n",
    "#Count Vectorize\n",
    "ngram = (1,3)\n",
    "train_data_tri, test_data_tri = count_vectorizer(X_train, X_test, ngram)\n",
    "\n",
    "#Tfidf Vectorize\n",
    "#ngram = (1,1)\n",
    "#train_data_tfidf_uni, test_data_tfidf_uni = tfidf_vectorizer(X_train, X_test, ngram)\n",
    "\n",
    "#Tfidf Vectorize\n",
    "#ngram = (1,2)\n",
    "#train_data_tfidf_bi, test_data_tfidf_bi = tfidf_vectorizer(X_train, X_test, ngram)\n",
    "\n",
    "#Tfidf Vectorize\n",
    "ngram = (1,3)\n",
    "train_data_tfidf_tri, test_data_tfidf_tri = tfidf_vectorizer(X_train, X_test, ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizedData-MLP.pkl', 'wb') as f:\n",
    "        obj = (train_data_tri,\n",
    "               test_data_tri,\n",
    "               train_data_tfidf_tri,\n",
    "               test_data_tfidf_tri,\n",
    "               y_train,\n",
    "               y_test)\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data= pd.read_pickle(\"vectorizedData-MLP.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please check the index for the arrays if not using \"vectorizedData-MLP.pkl\"\n",
    "#Trigram - countvector best model \n",
    "train_data = vector_data[0] \n",
    "test_data = vector_data[1]\n",
    "\n",
    "#Trigram - tfidf best model\n",
    "train_data_tfidf = vector_data[2]\n",
    "test_data_tfidf = vector_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = vector_data[4]\n",
    "y_test = vector_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_matrix(y_test, y_pred):\n",
    "    #y_pred = y_pred.astype(int)\n",
    "    #y_test = y_test.astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f_score, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "    return accuracy, precision, recall, f_score \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier CountVec Tri Train - Hidden Layers different\n",
      "accuracy=  0.9612083333333333\n",
      "precision=  0.9612124694697841\n",
      "recall=  0.961331688500451\n",
      "f_score=  0.9612059781455725\n",
      "\n",
      "\n",
      "MLP Classifier CountVec Tri Test - Hidden Layers different\n",
      "accuracy=  0.9435\n",
      "precision=  0.9435198838733749\n",
      "recall=  0.9435241713542074\n",
      "f_score=  0.9434999858749966\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_countvec = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(30,30,30), random_state=1,max_iter=400)\n",
    "\n",
    "clf_countvec.fit(train_data_tri, y_train['label'])\n",
    "\n",
    "y_pred_countvec_train = clf_countvec.predict(train_data_tri)\n",
    "\n",
    "accuracy_countvec_train, precision_countvec_train, recall_countvec_train, f_score_countvec_train = evaluation_matrix(y_train, y_pred_countvec_train)\n",
    "\n",
    "print('MLP Classifier CountVec Tri Train - Hidden Layers different')\n",
    "print('accuracy= ', accuracy_countvec_train)\n",
    "print('precision= ', precision_countvec_train)\n",
    "print('recall= ', recall_countvec_train)\n",
    "print('f_score= ', f_score_countvec_train)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "y_pred_countvec_test = clf_countvec.predict(test_data_tri)\n",
    "\n",
    "accuracy_countvec_test, precision_countvec_test, recall_countvec_test, f_score_countvec_test = evaluation_matrix(y_test, y_pred_countvec_test)\n",
    "\n",
    "print('MLP Classifier CountVec Tri Test - Hidden Layers different')\n",
    "print('accuracy= ', accuracy_countvec_test)\n",
    "print('precision= ', precision_countvec_test)\n",
    "print('recall= ', recall_countvec_test)\n",
    "print('f_score= ', f_score_countvec_test)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier TFIDF Tri Train - Hidden Layers different\n",
      "accuracy=  0.9996666666666667\n",
      "precision=  0.9996639583073244\n",
      "recall=  0.9996692616689438\n",
      "f_score=  0.9996665821985082\n",
      "\n",
      "\n",
      "MLP Classifier TFIDF Tri Test - Hidden Layers different\n",
      "accuracy=  0.9515\n",
      "precision=  0.9514993870358726\n",
      "recall=  0.9514977314910291\n",
      "f_score=  0.951498532830618\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tfidf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(30,30,30), random_state=1,max_iter=400)\n",
    "\n",
    "clf_tfidf.fit(train_data_tfidf_tri, y_train['label'])\n",
    "\n",
    "y_pred_tfidf_train = clf_tfidf.predict(train_data_tfidf_tri)\n",
    "\n",
    "accuracy_tfidf_train, precision_tfidf_train, recall_tfidf_train, f_score_tfidf_train = evaluation_matrix(y_train, y_pred_tfidf_train)\n",
    "\n",
    "print('MLP Classifier TFIDF Tri Train - Hidden Layers different')\n",
    "print('accuracy= ', accuracy_tfidf_train)\n",
    "print('precision= ', precision_tfidf_train)\n",
    "print('recall= ', recall_tfidf_train)\n",
    "print('f_score= ', f_score_tfidf_train)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "y_pred_tfidf_test = clf_tfidf.predict(test_data_tfidf_tri)\n",
    "\n",
    "accuracy_tfidf_test, precision_tfidf_test, recall_tfidf_test, f_score_tfidf_test = evaluation_matrix(y_test, y_pred_tfidf_test)\n",
    "\n",
    "print('MLP Classifier TFIDF Tri Test - Hidden Layers different')\n",
    "print('accuracy= ', accuracy_tfidf_test)\n",
    "print('precision= ', precision_tfidf_test)\n",
    "print('recall= ', recall_tfidf_test)\n",
    "print('f_score= ', f_score_tfidf_test)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model_countvec_tri_mlp.sav'\n",
    "pickle.dump(clf_countvec, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename_tfidf = 'finalized_model_tfidf_tri_mlp.sav'\n",
    "pickle.dump(clf_tfidf, open(filename_tfidf, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVec Test\n",
      "accuracy=  0.9435\n",
      "precision=  0.9435198838733749\n",
      "recall=  0.9435241713542074\n",
      "f_score=  0.9434999858749966\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "y_pred = loaded_model.predict(test_data)\n",
    "accuracy, precision, recall, f_score = evaluation_matrix(y_test, y_pred)\n",
    "\n",
    "print('CountVec Test')\n",
    "print('accuracy= ', accuracy)\n",
    "print('precision= ', precision)\n",
    "print('recall= ', recall)\n",
    "print('f_score= ', f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf test\n",
      "accuracy=  0.9515\n",
      "precision=  0.9514993870358726\n",
      "recall=  0.9514977314910291\n",
      "f_score=  0.951498532830618\n"
     ]
    }
   ],
   "source": [
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model_tfidf = pickle.load(open(filename_tfidf, 'rb'))\n",
    "y_pred_tfidf = loaded_model_tfidf.predict(test_data_tfidf)\n",
    "accuracy_tfidf, precision_tfidf, recall_tfidf, f_score_tfidf = evaluation_matrix(y_test, y_pred_tfidf)\n",
    "\n",
    "print('Tfidf test')\n",
    "print('accuracy= ', accuracy_tfidf)\n",
    "print('precision= ', precision_tfidf)\n",
    "print('recall= ', recall_tfidf)\n",
    "print('f_score= ', f_score_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.977992, 0.022008],\n",
       "       [0.158580, 0.841420],\n",
       "       [0.001509, 0.998491],\n",
       "       ...,\n",
       "       [0.002618, 0.997382],\n",
       "       [0.000001, 0.999999],\n",
       "       [0.008405, 0.991595]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = loaded_model.predict_proba(test_data)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
